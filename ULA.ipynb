{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip \n",
    "%pip install --upgrade jax \n",
    "%pip install \"flax[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp \n",
    "from jax import random\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from jax.random import PRNGKey, split\n",
    "from typing import Optional, Callable, List\n",
    "import numpyro.distributions as dist\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ULA_util import (\n",
    "    MultivariateNormalDiag,\n",
    "    GaussianMixture,\n",
    "    AnnealingSchedule,\n",
    "    StepSizeMLP,\n",
    "    ResidualBlock,\n",
    "    ScoreNetwork,\n",
    "    UnadjustedLangevin,\n",
    "    sigmoid \n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "pi_0 = MultivariateNormalDiag(loc=jnp.array([0.0]), scale_diag=jnp.array([1.0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnadjustedLangevin(eqx.Module):\n",
    "    pi_0: MultivariateNormalDiag\n",
    "    gamma: Callable[[jnp.ndarray], float]\n",
    "\n",
    "    schedule: AnnealingSchedule\n",
    "    stepsize_model: StepSizeMLP\n",
    "    n_steps: int\n",
    "\n",
    "    def gamma_k(self, k: int, x: jnp.ndarray) -> float:\n",
    "        betas = self.schedule.compute_betas()  \n",
    "        beta_k = betas[k]\n",
    "        return beta_k*self.gamma(x) + (1.0 - beta_k)*self.pi_0.log_prob(x)\n",
    "\n",
    "    def forward_kernel(self, k: int, x_prev: jnp.ndarray):\n",
    "        delta_k = self.stepsize_model(k)\n",
    "        grad_log = jax.grad(self.gamma_k, argnums=1)(k, x_prev)\n",
    "        mean = x_prev + delta_k * grad_log\n",
    "        stdev = jnp.sqrt(2.0*delta_k)\n",
    "        return mean, stdev\n",
    "\n",
    "    def log_prob_F_k(self, k: int, x_curr: jnp.ndarray, x_prev: jnp.ndarray) -> float:\n",
    "        mean, stdev = self.forward_kernel(k, x_prev)\n",
    "        d = x_curr.size\n",
    "        log_det = d*jnp.log(stdev**2)\n",
    "        log_norm = -0.5*d*jnp.log(2*jnp.pi) - 0.5*log_det\n",
    "        diff = x_curr - mean\n",
    "        quad = 0.5*jnp.sum((diff**2)/(stdev**2))\n",
    "        return log_norm - quad\n",
    "\n",
    "    def get_log_weight(self, key: jax.random.PRNGKey) -> float:\n",
    "        x0 = self.pi_0.sample(key)\n",
    "        log_w = - self.pi_0.log_prob(x0)\n",
    "        x_prev = x0\n",
    "\n",
    "        for k in range(1, self.n_steps+1):\n",
    "            key, subkey = jax.random.split(key)\n",
    "            mean, stdev = self.forward_kernel(k, x_prev)\n",
    "            x_k = mean + stdev*jax.random.normal(subkey, shape=x_prev.shape)\n",
    "            log_B = self.log_prob_F_k(k, x_prev, x_k)  \n",
    "            log_F = self.log_prob_F_k(k, x_k, x_prev)\n",
    "            log_w += (log_B - log_F)\n",
    "            x_prev = x_k\n",
    "\n",
    "        log_w += self.gamma(x_prev)\n",
    "        return log_w\n",
    "\n",
    "    def compute_log_Z(self, key: jax.random.PRNGKey, n_samples=512) -> float:\n",
    "        keys = jax.random.split(key, n_samples)\n",
    "        log_ws = jax.vmap(self.get_log_weight)(keys)\n",
    "        max_lw = jnp.max(log_ws)\n",
    "        return max_lw + jnp.log(jnp.mean(jnp.exp(log_ws - max_lw)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    key = jax.random.PRNGKey(0)\n",
    "    dim = 20\n",
    "    n_steps = 64\n",
    "\n",
    "    pi_0 = MultivariateNormalDiag(loc=jnp.zeros(dim), scale_diag=3*jnp.ones(dim))\n",
    "    target = GaussianMixture(dim, n_components=8, key=key)\n",
    "\n",
    "    def gamma_fn(x):\n",
    "        return target.log_prob(x)\n",
    "\n",
    "    key_sch, key_step = jax.random.split(key)\n",
    "    schedule = AnnealingSchedule(n_steps, key_sch)\n",
    "    stepmlp  = StepSizeMLP(n_steps, key_step)\n",
    "\n",
    "    ula = UnadjustedLangevin(\n",
    "        pi_0=pi_0,\n",
    "        gamma=gamma_fn,\n",
    "        schedule=schedule,\n",
    "        stepsize_model=stepmlp,\n",
    "        n_steps=n_steps\n",
    "    )\n",
    "\n",
    "    params = eqx.filter(ula, eqx.is_array)\n",
    "    opt = optax.adam(1e-3)\n",
    "    opt_state = opt.init(params)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def loss_fn(ula: UnadjustedLangevin, key):\n",
    "        logZ_est = ula.compute_log_Z(key, n_samples=128)\n",
    "        return -logZ_est\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def train_step(ula: UnadjustedLangevin, opt_state, key):\n",
    "        l, grads = eqx.filter_value_and_grad(loss_fn)(ula, key)\n",
    "        updates, opt_state = opt.update(grads, opt_state, params=eqx.filter(ula, eqx.is_array))\n",
    "        ula = eqx.apply_updates(ula, updates)\n",
    "        return l, ula, opt_state\n",
    "\n",
    "    steps = 2001\n",
    "    for step_i in range(steps):\n",
    "        key, subkey = jax.random.split(key)\n",
    "        loss_val, ula, opt_state = train_step(ula, opt_state, subkey)\n",
    "        if step_i % 500==0:\n",
    "            print(f\"step={step_i}, neg logZ={float(loss_val):.4f}\")\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    final_logZ = ula.compute_log_Z(subkey, n_samples=16384)\n",
    "    print(\"Final logZ estimate:\", float(final_logZ))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
